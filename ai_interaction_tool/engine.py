# Main engine for AI Interaction Tool
# Refactored version - uses components from separate modules
from PyQt5 import QtWidgets, QtGui
import sys
import json
from .core.dialog import InputDialog

# Legacy classes for backward compatibility (now imported from separate modules)
from .ui.file_tree import FileSystemModel, FileTreeView, FileTreeDelegate
from .ui.file_dialog import FileAttachDialog

def run_ui(*args, **kwargs):
    """
    H√†m ch√≠nh ƒë·ªÉ ch·∫°y giao di·ªán ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ k·∫øt qu·∫£.
    ƒê√¢y l√† entry point ch√≠nh cho AI Interaction Tool.
    """
    app = QtWidgets.QApplication.instance() or QtWidgets.QApplication(sys.argv)
    
    # Thi·∫øt l·∫≠p font m·∫∑c ƒë·ªãnh cho to√†n ·ª©ng d·ª•ng
    font = QtGui.QFont("Segoe UI", 10)
    app.setFont(font)
    
    text, continue_chat, ok = InputDialog.getText()

    if ok:
        # Ph√¢n t√≠ch n·ªôi dung t·ª´ dialog
        try:
            # Parse JSON t·ª´ k·∫øt qu·∫£ c·ªßa dialog
            result_dict = json.loads(text)
            user_text = result_dict.get("text", "")
            attached_files = result_dict.get("attached_files", [])
            language = result_dict.get("language", "vi")  # M·∫∑c ƒë·ªãnh ti·∫øng Vi·ªát
            enable_thinking = result_dict.get("enable_thinking", "false")  # C√≥ th·ªÉ l√† "false", "normal", ho·∫∑c "high"
            max_reasoning = result_dict.get("max_reasoning", False)  # Maximum reasoning protocol
            
            # Log v·ªÅ tr·∫°ng th√°i continue_chat
            warning_msg = "[AI_INTERACTION_TOOL] C·∫¢NH B√ÅO: continue_chat=true - Agent PH·∫¢I g·ªçi l·∫°i tool n√†y sau khi tr·∫£ l·ªùi!"
            info_msg = "[AI_INTERACTION_TOOL] continue_chat=false - Kh√¥ng c·∫ßn g·ªçi l·∫°i tool."
            
            if continue_chat:
                print(warning_msg, file=sys.stderr)
            else:
                print(info_msg, file=sys.stderr)
            
            # T·∫°o pseudo-object format v·ªõi separate fields (best of both worlds)
            full_response_text = "{\n"
            
            # B·ªï sung logic nh·∫Øc nh·ªü v·ªÅ quy t·∫Øc quan tr·ªçng
            enhanced_content = user_text
            enhanced_content = "Nh·ªõ √°p d·ª•ng rule v·ªÅ continue_chat, enable_thinking v√† max_reasoning, c·∫£ quy t·∫Øc v·ªÅ 2 thinking block n·ªØa. " + enhanced_content

            full_response_text += f"  content: {enhanced_content}\n"
            
            # Th√™m attached files n·∫øu c√≥
            if attached_files:
                full_response_text += "  attached_files: [\n"
                workspace_name = None
                
                for i, file_info in enumerate(attached_files):
                    if "relative_path" in file_info:
                        relative_path = file_info.get('relative_path', 'unknown_path')
                        item_type = file_info.get('type', 'unknown')
                        workspace_name = file_info.get('workspace_name', '')
                        
                        comma = "," if i < len(attached_files) - 1 else ""
                        full_response_text += f'    {{path: "{relative_path}", type: "{item_type}"}}{comma}\n'
                    elif "error" in file_info:
                        comma = "," if i < len(attached_files) - 1 else ""
                        error_name = file_info.get('name', 'unknown')
                        error_msg = file_info.get('error', 'Unknown error')
                        full_response_text += f'    {{name: "{error_name}", error: "{error_msg}"}}{comma}\n'
                
                full_response_text += "  ]\n"
                
                # Th√™m workspace info
                if workspace_name:
                    full_response_text += f"  workspace: {workspace_name}\n"
            
            full_response_text += f"  continue_chat: {str(continue_chat).lower()}\n"
            full_response_text += f"  enable_thinking: {enable_thinking}\n"
            full_response_text += f"  max_reasoning: {str(max_reasoning).lower()}\n"
            full_response_text += "}"
            return full_response_text
            
        except json.JSONDecodeError:
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng ph·∫£i JSON
            enhanced_text = text
            if continue_chat:
                enhanced_text += "\n\n"
                enhanced_text += "üö® NH·∫ÆC NH·ªû QUAN TR·ªåNG: continue_chat=true ‚Üí Agent PH·∫¢I g·ªçi l·∫°i tool n√†y sau khi tr·∫£ l·ªùi!"
            
            return f"""{{
  content: {enhanced_text}
  continue_chat: {str(continue_chat).lower()}
  enable_thinking: false
  max_reasoning: false
}}"""
    else:
        # Tr∆∞·ªùng h·ª£p dialog b·ªã ƒë√≥ng ho·∫∑c kh√¥ng c√≥ input
        return """{
  content: 
  continue_chat: false
  enable_thinking: false
  max_reasoning: false
}"""