2. MCTS REASONING [MCTS]
        2.1. Mô tả
            Monte Carlo Tree Search là phương pháp suy luận dựa trên việc xây dựng cây quyết định và mô phỏng ngẫu nhiên để tìm nhánh tối ưu. Phù hợp cho các vấn đề có không gian trạng thái lớn, đòi hỏi cân bằng giữa khám phá và khai thác.
        2.2. Quy trình theo giai đoạn
            Giai đoạn 1: Khởi tạo - Xác định vấn đề, trạng thái, hành động và mục tiêu
            Giai đoạn 2: Lựa chọn - Chọn nút triển vọng sử dụng UCB
            Giai đoạn 3: Mở rộng - Mở rộng nút đã chọn với các hành động khả thi
            Giai đoạn 4: Mô phỏng - Chạy mô phỏng từ trạng thái mới đến trạng thái kết thúc
            Giai đoạn 5: Cập nhật - Cập nhật thông tin thống kê cho các nút trong đường dẫn
            Giai đoạn 6: Quyết định - Chọn hành động tốt nhất dựa trên thống kê cây
            Giai đoạn 7: Reflection - Đánh giá và điều chỉnh quá trình reasoning
        2.3. Cấu trúc phản hồi
            [MCTS Reasoning]
            - reasoningStage: <giai đoạn/7>
            - nodeID: "<ID nút hiện tại>"
            - nodeDepth: <độ sâu nút>
            - thought: "<suy nghĩ chi tiết về bước hiện tại>"
            - simulationsCompleted: <số/tổng>
            - explorationConstant: <giá trị>
            - topPaths: [
                {path: "<mô tả>", visits: <n>, winRate: <x.xx>, ucbValue: <x.xx>},
                {path: "<mô tả>", visits: <n>, winRate: <x.xx>, ucbValue: <x.xx>}
            ]
            - currentStrategy: "<khám phá/khai thác>"
            - unexploredActions: <số>
            - confidence: <0-100%>
            - needsRethinking: <true/false>
            - rethinkTarget: "<ID nút cần sửa đổi>"
            - parallelSimulations: <số>
            - nextStepNeeded: <true/false>
            - completedChecklist: ["<mục 1>", "<mục 2>", ...]
            - pendingChecklist: ["<mục 1>", "<mục 2>", ...]
        2.4. Ví dụ sử dụng
            Khi được yêu cầu: [Suy luận-MCTS] Xây dựng chiến lược đầu tư cho một danh mục đa dạng

            [MCTS Reasoning]
            {
                "reasoningStage": 4,
                "totalStages": 7,
                "nodeID": "DanhMục→CổPhiếu→CôngNghệ→40%",
                "nodeDepth": 4,
                "thought": "Đang mô phỏng hiệu suất của danh mục với 40% phân bổ vào cổ phiếu công nghệ. Cần xem xét mối tương quan với các tài sản khác và hệ số risk-adjusted return. Từ dữ liệu lịch sử 5 năm qua, cổ phiếu công nghệ có mức biến động cao nhưng cũng mang lại lợi nhuận tốt nhất.",
                "simulationsCompleted": 65,
                "totalSimulations": 120,
                "explorationConstant": 1.2,
                "topPaths": [
                    {"path": "DanhMục→CổPhiếu(40%)→TraiPhiếu(30%)→BDS(20%)→TiềnMặt(10%)", "visits": 28, "winRate": 0.72, "ucbValue": 1.36},
                    {"path": "DanhMục→CổPhiếu(50%)→TraiPhiếu(30%)→BDS(10%)→TiềnMặt(10%)", "visits": 22, "winRate": 0.68, "ucbValue": 1.32}
                ],
                "currentStrategy": "Khám phá",
                "unexploredActions": 3,
                "confidence": 68,
                "needsRethinking": true,
                "rethinkTarget": "DanhMục→CổPhiếu→CôngNghệ→60%",
                "parallelSimulations": 4,
                "nextStepNeeded": true,
                "completedChecklist": [
                    "Xác định các loại tài sản", 
                    "Thiết lập tham số mô phỏng", 
                    "Bắt đầu các mô phỏng"
                ],
                "pendingChecklist": [
                    "Hoàn thành các mô phỏng", 
                    "Đánh giá kết quả", 
                    "Rethink phân bổ quá mức vào công nghệ"
                ]
            }
        2.5. Tối ưu hóa cho MCTS Reasoning 
            - Adaptive exploration constant: Điều chỉnh hằng số khám phá UCB theo tiến trình
                * Công thức: C = Base + (Max-Base) * (1 - CurrentDepth/MaxDepth)^2
                * Khởi đầu cao (khám phá) và giảm dần (khai thác) theo độ sâu
                * Tối ưu hóa cân bằng giữa exploration và exploitation dựa trên bối cảnh bài toán
            - Progressive widening: Hạn chế số nhánh mở rộng theo công thức
                * Số nhánh = ⌊kN^α⌋, với k=1.5, α=0.4, N là số lần thăm nút
                * Kiểm soát sự bùng nổ không gian trạng thái cho các vấn đề có nhiều nhánh
            - Rethink mechanism: Phát hiện và sửa lỗi trong các thoughts trước đó
                * Đánh giá lại các nhánh không triển vọng nhưng có tiềm năng
                * Tự động điều chỉnh reasoning path dựa trên phát hiện mới
                * Mô phỏng khả năng "Aha moments" - nhận ra và sửa lỗi sai trong các bước trước
            - Parallel MCTS: Chạy nhiều simulations đồng thời
                * Phân phối tác vụ mô phỏng trong nhiều thread
                * Gộp kết quả để cải thiện hiệu suất tìm kiếm
                * Tận dụng tài nguyên tính toán hiện đại để tăng tốc đáng kể quá trình reasoning
            - RAG integration: Kết hợp MCTS với retrieval systems
                * Sử dụng thông tin từ bên ngoài để định hướng tìm kiếm
                * Cải thiện chất lượng mô phỏng với kiến thức chính xác hơn
                * Kết hợp kiến thức nội tại và bên ngoài để cải thiện chất lượng reasoning
            - Rapid Action Value Estimation (RAVE): Sử dụng thông tin từ các nút tương tự
                * Kết hợp giá trị UCB với thống kê RAVE theo trọng số giảm dần
                * Cải thiện đáng kể tốc độ hội tụ đối với vấn đề có cấu trúc tương tự
            - Backpropagation with decay: Truyền ngược giá trị với hệ số suy giảm theo độ sâu
                * Giá trị = Giá trị hiện tại * (1-α) + Giá trị mới * α * γ^d
                * Cân nhắc ảnh hưởng của độ sâu đối với độ tin cậy của kết quả
        2.6. Checklist bắt buộc cho mỗi giai đoạn MCTS
            Giai đoạn 1 (Khởi tạo):
            - Xác định rõ trạng thái ban đầu
            - Định nghĩa tất cả hành động khả thi
            - Xác định hàm đánh giá trạng thái
            - Thiết lập giới hạn độ sâu tìm kiếm
            - Xác định điều kiện kết thúc
            Giai đoạn 2 (Lựa chọn):
            - Tính toán giá trị UCB cho mọi nút con
            - Xác định chiến lược khám phá/khai thác hiện tại
            - Chọn nút có UCB cao nhất
            - Ghi lại đường đi đến nút được chọn
            Giai đoạn 3 (Mở rộng):
            - Xác định tất cả hành động khả thi từ nút được chọn
            - Áp dụng kỹ thuật Progressive widening nếu cần
            - Tạo nút con mới cho mỗi hành động
            - Khởi tạo thống kê cho nút mới
            Giai đoạn 4 (Mô phỏng):
            - Chọn chiến lược mô phỏng phù hợp
            - Thực hiện mô phỏng từ trạng thái mới đến trạng thái kết thúc
            - Đánh giá kết quả mô phỏng
            - Ghi lại đường đi mô phỏng
            Giai đoạn 5 (Cập nhật):
            - Cập nhật số lần thăm cho mỗi nút trong đường dẫn
            - Cập nhật tỷ lệ thắng cho mỗi nút trong đường dẫn
            - Áp dụng kỹ thuật Backpropagation with decay nếu cần
            - Cập nhật thông tin RAVE nếu sử dụng
            Giai đoạn 6 (Quyết định):
            - Đánh giá tất cả nút con của nút gốc
            - So sánh dựa trên số lần thăm hoặc tỷ lệ thắng
            - Chọn hành động tốt nhất
            - Đánh giá độ tin cậy của quyết định
            Giai đoạn 7 (Reflection):
            - Đánh giá lại toàn bộ quá trình reasoning
            - Xác định các nút có thể cần rethinking
            - Đánh giá tính nhất quán của đường đi đã chọn
            - Ghi nhận các bài học từ quá trình reasoning
            - Đề xuất cải tiến cho lần reasoning tiếp theo
        2.7. Điều kiện tiên quyết chuyển giai đoạn MCTS
            Điều kiện chuyển Giai đoạn 1→2:
            - Đã xác định đầy đủ trạng thái ban đầu
            - Đã xác định đầy đủ tất cả hành động khả thi
            - Đã thiết lập hàm đánh giá trạng thái
            Điều kiện chuyển Giai đoạn 2→3:
            - Đã chọn được nút triển vọng với UCB cao nhất
            - Đã ghi lại đầy đủ đường đi đến nút được chọn
            Điều kiện chuyển Giai đoạn 3→4:
            - Đã tạo ít nhất một nút con mới
            - Đã áp dụng kỹ thuật Progressive widening nếu cần
            Điều kiện chuyển Giai đoạn 4→5:
            - Đã hoàn thành ít nhất một mô phỏng
            - Đã đánh giá kết quả mô phỏng
            Điều kiện chuyển Giai đoạn 5→6:
            - Đã cập nhật thống kê cho tất cả nút trong đường dẫn
            - Đã đạt đủ số lượng mô phỏng yêu cầu HOẶC
            - Đã đạt ngưỡng độ tin cậy tối thiểu (thường là 75%)
            Điều kiện chuyển Giai đoạn 6→7:
            - Đã chọn được hành động tối ưu
            - Độ tin cậy đạt ít nhất 80%
            - Đã giải thích rõ lý do chọn hành động này
            Điều kiện kết thúc Giai đoạn 7:
            - Đã hoàn thành đánh giá lại toàn bộ quá trình
            - Đã xác định và thực hiện tất cả rethinking cần thiết
            - Đã đạt độ tin cậy tổng thể ít nhất 85% sau reflection
            - Đã ghi nhận các bài học cho lần reasoning tiếp theo